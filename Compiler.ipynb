{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime as dt\n",
    "import pytz\n",
    "from sklearn.utils import resample\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor as MPR\n",
    "from sklearn.preprocessing import Normalizer,StandardScaler,MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "Root = 'C:/FishIsland_2017/'\n",
    "\n",
    "\n",
    "FluxFolder='FluxResults/ProperWindSpeeds/'\n",
    "\n",
    "TenHz_Path = Root+FluxFolder+'10Hz/eddypro_10Hz_full_output_2018-03-25T172145_adv.csv'\n",
    "OneHz_Path = Root+FluxFolder+'1Hz/eddypro_1Hz_full_output_2018-03-25T142146_adv.csv'\n",
    "\n",
    "Met_Path = Root+'MetStationData/CR1000_ClimateData_Updated.txt'\n",
    "Soil_Path = Root+'SoilStationData/Soil_Data.csv'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def Light_Response(PPFD,alpha,beta,gamma):\n",
    "    return(-(beta+gamma)*(1-np.exp((-alpha*PPFD)/(beta+gamma)))+gamma)\n",
    "\n",
    "def Light_Response_Temp(X,alpha,beta,r1,r2,r3):\n",
    "    PPFD,temp = X\n",
    "    return(-(beta+(1/(r1*r2**temp+r3)))*(1-np.exp((-alpha*PPFD)/(beta+(1/(r1*r2**temp+r3)))))+(1/(r1*r2**temp+r3)))\n",
    "\n",
    "def Light_Response_Temp2(X,alpha,beta,theta,r1,r2,r3):\n",
    "    PPFD,temp = X\n",
    "    return(-1/2*theta*(alpha*PPFD+beta-((alpha*PPFD+beta)**2-4*alpha*beta*theta*PPFD)**.5)+(1/(r1*r2**temp+r3)))\n",
    "#     return(-(beta+(1/(r1*r2**temp+r3)))*(1-np.exp((-alpha*PPFD)/(beta+(1/(r1*r2**temp+r3)))))+(1/(r1*r2**temp+r3)))\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SimpleANN(Data,keys,node,iters,Verbose=True,Plot=False):\n",
    "    Data_2 = Data[keys].dropna()\n",
    "    X = Data_2[keys[1:]].values\n",
    "    y = Data_2[keys[0]].values\n",
    "    \n",
    "    Metric = []\n",
    "    Metric2 = []\n",
    "    for r in range(0,iters):\n",
    "        ANN=  Pipeline([('scaling', StandardScaler()), \n",
    "                ('MPR',  MPR(hidden_layer_sizes=(node),max_iter = 1000,activation='logistic',solver ='lbfgs',\n",
    "                learning_rate = 'adaptive',early_stopping=True,tol=1e-5,validation_fraction=.1,\n",
    "                             random_state = r,learning_rate_init =1e-3))])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=r)\n",
    "        \n",
    "        ANN.fit(X_train,y_train)    \n",
    "        y_pred = ANN.predict(X_test)\n",
    "        if Plot == True:\n",
    "            plt.scatter(y_test,y_pred)\n",
    "            plt.xlabel('pred')\n",
    "            plt.ylabel('true')\n",
    "            plt.xlim(y.min(),y.max())\n",
    "            plt.ylim(y.min(),y.max())\n",
    "        Metric2.append(metrics.mean_absolute_error(y_test,y_pred))\n",
    "        Metric.append(metrics.r2_score(y_test,y_pred))\n",
    "        pred = ANN.predict(Data[keys[1:]].dropna().values)\n",
    "        if Verbose == True:\n",
    "            print(ANN.named_steps.MPR.loss_,metrics.r2_score(y_test,y_pred))\n",
    "        if r == 0:\n",
    "            Pred = pred\n",
    "        else:\n",
    "            Pred += pred\n",
    "    Pred /=(r+1)\n",
    "    Metric = np.asanyarray(Metric)\n",
    "    Metric2 = np.asanyarray(Metric2)\n",
    "    if Verbose == True:\n",
    "        print(Metric2.mean())\n",
    "    return(Metric.mean(),Metric2.mean(),Pred,Metric2.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Compile:\n",
    "    def __init__(self,Flux_Paths,Met,Soil):\n",
    "        self.Fluxes = ['H','LE','co2_flux','ch4_flux']\n",
    "        Flux_10 = self.Format(pd.read_csv(Flux_Paths[0],delimiter = ',',skiprows = 0,parse_dates={'datetime':[1,2]},header = 1,na_values = -9999),v=1,drop = [0,1])\n",
    "        Flux_1 = self.Format(pd.read_csv(Flux_Paths[1],delimiter = ',',skiprows = 0,parse_dates={'datetime':[1,2]},header = 1,na_values = -9999),v=1,drop = [0,1])\n",
    "        Flux_10['Hz']=10\n",
    "        Flux_1['Hz'] = 1\n",
    "        Flux = Flux_1.append(Flux_10)\n",
    "        Met = self.Format(pd.read_csv(Met,delimiter = ',',skiprows = 1,parse_dates={'datetime':[0]},header = 0),v=2,drop = [0])\n",
    "        Soil = self.Format(pd.read_csv(Soil,delimiter = ',',skiprows = 0,parse_dates={'datetime':[0]},header = 0),v=0,drop = [0])\n",
    "\n",
    "        self.RawData = pd.concat([Flux,Met,Soil],axis = 1, join = 'outer')\n",
    "        self.VeryRawData = self.RawData.copy()\n",
    "        self.StorageCorrection()\n",
    "        for var in self.Fluxes:\n",
    "            self.RawData[var+'_drop'] = 0\n",
    "        self.RawData['Minute'] = self.RawData.index.hour*60+self.RawData.index.minute\n",
    "        self.Wind_Bins(30)\n",
    "        self.PPFD_Bins(100)\n",
    "        self.RawData['Day'] = np.floor(self.RawData['DOY'])\n",
    "        \n",
    "        Mt = pytz.timezone('US/Mountain')\n",
    "        self.RawData['UTC'] = self.RawData.index.tz_localize(pytz.utc).tz_convert(Mt)\n",
    "        self.Rain_Check([.5,0])\n",
    "\n",
    "    def Format(self,df,v,drop):\n",
    "        df = df.ix[v:]\n",
    "        df = df.set_index(pd.DatetimeIndex(df.datetime))\n",
    "        df = df.drop(df.columns[drop],axis=1)\n",
    "        df = df.astype(float)\n",
    "        return(df)\n",
    "    \n",
    "    def Date_Drop(self,Date,Vars):\n",
    "        if Vars == 'All':\n",
    "            self.RawData = self.RawData.drop(self.RawData.loc[(self.RawData.index>Date[0])&(self.RawData.index<Date[1])].index)\n",
    "        else:\n",
    "            self.RawData.loc[(self.RawData.index>Date[0])&(self.RawData.index<Date[1]),[Vars]]=np.nan\n",
    "            \n",
    "    def Wind_Bins(self,Bins):\n",
    "        self.bins = np.arange(0,360.1,Bins)\n",
    "        self.RawData['Dir'] = pd.cut(self.RawData['wind_dir'],bins=self.bins,labels = (self.bins[0:-1]+self.bins[1:])/2)\n",
    "        \n",
    "    def ustar_Bins(self,Bins,LightFilter = {'Var':'PPFD_Avg','Thresh':10},\n",
    "               uFilter={'Var':'co2_flux','Plot':False},BootStraps={'Repetitions':100,'n_samples':10000}):\n",
    "        def Rcalc(Grp,thrsh=0.95):\n",
    "            Ratios=[]\n",
    "            for G in Grp.index:\n",
    "                m1 = Grp[uFilter['Var']][Grp.index==G].values[0]\n",
    "                m2 = Grp[uFilter['Var']][Grp.index>G].mean()\n",
    "                Ratios.append(m1/m2)\n",
    "            Ratios = np.asanyarray(Ratios)\n",
    "            try:\n",
    "                uThresh = Grp.index[np.where(Ratios>=.95)[0]][0]\n",
    "            except:\n",
    "                print('Could not find u* thersh, defaulting to 0.1')\n",
    "                uThresh = 0.1\n",
    "            return(uThresh)\n",
    "            \n",
    "        self.uFilterData = self.RawData[self.RawData[LightFilter['Var']]<=LightFilter['Thresh']]\n",
    "        self.bins = self.uFilterData['u*'].quantile(np.arange(0,Bins,1)/Bins).values\n",
    "        self.uFilterData['u*bin'] = pd.cut(self.uFilterData['u*'],bins=self.bins,labels = (self.bins[0:-1]+self.bins[1:])/2)\n",
    "        Grp = self.uFilterData.groupby(['u*bin']).mean()\n",
    "        GrpC = self.uFilterData.groupby(['u*bin']).size()\n",
    "        GrpSE = self.uFilterData.groupby(['u*bin']).std()/(GrpC)**.5\n",
    "        self.uThresh_SampSize = GrpC.sum()\n",
    "        \n",
    "        self.uThresh = Rcalc(Grp)\n",
    "        self.BootStraps = {}\n",
    "        for i in range(BootStraps['Repetitions']):\n",
    "            Samp = resample(self.RawData,replace=True,n_samples=BootStraps['n_samples'])\n",
    "            Samp = Samp[Samp[LightFilter['Var']]<=LightFilter['Thresh']]\n",
    "            bins = Samp['u*'].quantile(np.arange(0,Bins,1)/Bins).values\n",
    "            Samp['u*bin'] = pd.cut(Samp['u*'],bins=bins,labels = (bins[0:-1]+bins[1:])/2)\n",
    "            self.BootStraps[str(i)] = Samp\n",
    "        Ge = []\n",
    "        for i in Comp.BootStraps:\n",
    "            G = Comp.BootStraps[i].groupby(['u*bin']).mean()\n",
    "            Ge.append(Rcalc(G))\n",
    "        Ge = np.asanyarray(Ge)\n",
    "        self.Pct = {'5%':np.percentile(Ge,[5]),'50%':np.percentile(Ge,[50]),'95%':np.percentile(Ge,[95])}\n",
    "        if uFilter['Plot'] == True:\n",
    "            plt.figure(figsize=(6,5))\n",
    "            plt.errorbar(Grp['u*'],Grp[uFilter['Var']],yerr=GrpSE['u*'],label = 'Mean +- 1SE')\n",
    "            def Vlines(var,c,l):\n",
    "                plt.plot([var,var],[Grp[uFilter['Var']].min(),Grp[uFilter['Var']].max()],\n",
    "                         color = c,label=l)\n",
    "            Vlines(self.uThresh,c='red',l='Mean')\n",
    "            Vlines(self.Pct['5%'],c='green',l='5%')\n",
    "            Vlines(self.Pct['50%'],c='yellow',l='50%')\n",
    "            Vlines(self.Pct['95%'],c='blue',l='95%')\n",
    "            plt.legend()\n",
    "            plt.title('u* Thershold & Bootstrapped 95% CI')\n",
    "            plt.grid()\n",
    "        \n",
    "    def PPFD_Bins(self,Bins):\n",
    "        self.bins = np.arange(0,self.RawData['PPFD_Avg'].max()+1,Bins)\n",
    "        self.RawData['Photon_Flux'] = pd.cut(self.RawData['PPFD_Avg'],bins=self.bins,labels = (self.bins[0:-1]+self.bins[1:])/2)\n",
    "\n",
    "    def Rain_Check(self,thresh):\n",
    "        self.RawData['Rain_diff'] = self.RawData['Rain_mm_Tot'].diff()\n",
    "        for var in self.Fluxes:\n",
    "            if var!='ch4_flux':\n",
    "                self.RawData.loc[self.RawData['Rain_mm_Tot']>thresh[0],[var,var+'_drop']]=[np.nan,1]\n",
    "            else:\n",
    "                self.RawData.loc[self.RawData['Rain_mm_Tot']>thresh[1],[var,var+'_drop']]=[np.nan,1]\n",
    "        \n",
    "    def Spike_Removal(self,z_thresh,AltData=None):\n",
    "        def Remove(series):\n",
    "            di1 = series.diff()\n",
    "            di1[:-1] = di1[1:]\n",
    "            di = di1.diff()\n",
    "            MD = di.median()\n",
    "            MAD = np.abs(di-MD).median()\n",
    "            F1 = di<MD-(z_thresh*MAD/0.6745)\n",
    "            F2 = di>MD+(z_thresh*MAD/0.6745)\n",
    "            series.loc[F1==True]=np.nan\n",
    "            series.loc[F2==True]=np.nan\n",
    "            Droppers = series.index[np.isnan(series)==True]\n",
    "            VAR = self.RawData[var]\n",
    "            VAR.ix[Droppers] = np.nan\n",
    "            dina = VAR.diff()\n",
    "            dina[:-1] = dina[1:]\n",
    "            dina2 = VAR.diff()\n",
    "            NaMid = VAR.index[((np.isnan(dina)==True)&(np.isnan(dina2)==True))]\n",
    "            VAR.ix[NaMid] = np.nan\n",
    "            return(VAR)       \n",
    "        \n",
    "        if AltData == None:\n",
    "            for var in self.Fluxes:\n",
    "                self.RawData[var]=Remove(self.RawData[var].dropna())\n",
    "        else:\n",
    "            AltData[var]=Remove(self.AltData[var].dropna())\n",
    "            return(AltData[0])\n",
    "        \n",
    "    def Wind_Filter(self,width):\n",
    "        for var in self.Fluxes:\n",
    "            self.RawData.loc[((self.RawData['wind_dir']>215-width)&(self.RawData['wind_dir']<215+width)),[var,var+'_drop']]=[np.nan,1]\n",
    "        \n",
    "    def StorageCorrection(self,Raw=True):\n",
    "        if Raw == False:\n",
    "            self.Data['fco2'] = self.Data['co2_flux']+self.Data['co2_strg']\n",
    "            self.Data['fch4'] = self.Data['ch4_flux']+self.Data['ch4_strg']\n",
    "        else:\n",
    "            self.RawData['fco2'] = self.RawData['co2_flux']+self.RawData['co2_strg']\n",
    "            self.RawData['fch4'] = self.RawData['ch4_flux']+self.RawData['ch4_strg']\n",
    "        \n",
    "    def Signal_Check(self,thresh):\n",
    "        self.RawData['ch4_noSSFilter'] = self.RawData['ch4_flux']\n",
    "        self.RawData.loc[self.RawData['rssi_77_mean']<thresh,['ch4_flux','ch4_flux_drop']] = [np.nan,1]\n",
    "    \n",
    "    def QC_Check(self,thresh):\n",
    "        for var in self.Fluxes:\n",
    "            self.RawData.loc[self.RawData['qc_'+var]>=thresh,[var,var+'_drop']]=[np.nan,1]\n",
    "            self.RawData.loc[np.isnan(self.RawData[var]) == True,[var+'_drop']]=1\n",
    "            \n",
    "    def Ustar_Drop(self,Override=None):\n",
    "        self.Data = self.RawData.copy()\n",
    "        if Override != None:\n",
    "            self.uThresh = Override\n",
    "        for var in self.Fluxes:\n",
    "            self.Data.loc[self.Data['u*']<self.uThresh,[var,var+'_drop']]=[np.nan,1]\n",
    "        self.StorageCorrection(Raw=False)\n",
    "\n",
    "## Initialize everything and parse the data\n",
    "Comp = Compile([TenHz_Path,OneHz_Path],Met_Path,Soil_Path)\n",
    "\n",
    "Drop = [['2017-06-01 15:00:00','2017-06-23 15:00:00'],\n",
    "['2017-08-28 00:00:00','2017-09-11 16:00:00'],\n",
    "['2017-09-12 07:30:00','2017-09-12 15:00:00']]\n",
    "Var = ['All','co2_flux','co2_flux']\n",
    "for drop,var in zip(Drop,Var):\n",
    "    Comp.Date_Drop(drop,Vars=var)\n",
    "Comp.QC_Check(2)\n",
    "Comp.Spike_Removal(z_thresh=5.5)\n",
    "Comp.Wind_Filter(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comp.ustar_Bins(30,{'Var':'PPFD_Avg','Thresh':20},{'Var':'ch4_flux','Plot':True},\n",
    "#                 {'Repetitions':100,'n_samples':10000})\n",
    "\n",
    "# print(Comp.uThresh,Comp.Pct,Comp.uThresh_SampSize)\n",
    "\n",
    "Comp.ustar_Bins(30,{'Var':'PPFD_Avg','Thresh':10},{'Var':'co2_flux','Plot':True},\n",
    "                {'Repetitions':100,'n_samples':10000})\n",
    "\n",
    "print(Comp.uThresh,Comp.Pct,Comp.uThresh_SampSize)\n",
    "\n",
    "# plt.ylim(-10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Comp.Ustar_Drop()\n",
    "Data = Comp.Data\n",
    "Data['WtrTbl_Range'] = Data['Table_1'].rolling(48).max()-Data['Table_1'].rolling(48).min()\n",
    "Data['Rain_1D'] = Data['Rain_mm_Tot'].rolling(48).sum()\n",
    "Data['Time']=Data.index.hour\n",
    "Data['fch4']*=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Temp = Data[['fco2','PPFD_Avg']].dropna()\n",
    "Temp = Data[['fco2','PPFD_Avg','Temp_2_5_1']].dropna()\n",
    "popt, pcov = curve_fit(Light_Response_Temp, (Temp['PPFD_Avg'].values,Temp['Temp_2_5_1'].values,), Temp['fco2'].values)\n",
    "popt2, pcov2 = curve_fit(Light_Response_Temp2, (Temp['PPFD_Avg'].values,Temp['Temp_2_5_1'].values,),\n",
    "                       Temp['fco2'].values,p0=(0.00716274,1.52597427,1,2.69368876,0.86723787,0.65435465))\n",
    "\n",
    "# pred = Light_Response_Temp((Temp['PPFD_Avg'],Temp['Temp_2_5_1']),popt[0],popt[1],popt[2],popt[3],popt[4])\n",
    "pred2 = Light_Response_Temp2((Temp['PPFD_Avg'],Temp['Temp_2_5_1']),popt2[0],popt2[1],popt2[2],popt2[3],popt2[4],popt2[5])\n",
    "\n",
    "\n",
    "\n",
    "r2 = (metrics.r2_score(Temp['fco2'].values,pred2))\n",
    "\n",
    "fig = plt.figure(figsize=(8,5.8))\n",
    "plt.scatter(Temp['PPFD_Avg'],Temp['fco2'],color='green',label='Observations',s=15)\n",
    "plt.scatter(Temp['PPFD_Avg'],pred2,color=(0.5,0.5,0.5),label='Estimated: r$^2$ = '+str(np.round(r2,2)),s=15)\n",
    "\n",
    "def add_subplot_axes(ax,rect,axisbg='w'):\n",
    "    fig = plt.gcf()\n",
    "    box = ax.get_position()\n",
    "    width = box.width\n",
    "    height = box.height\n",
    "    inax_position  = ax.transAxes.transform(rect[0:2])\n",
    "    transFigure = fig.transFigure.inverted()\n",
    "    infig_position = transFigure.transform(inax_position)    \n",
    "    x = infig_position[0]\n",
    "    y = infig_position[1]\n",
    "    width *= rect[2]\n",
    "    height *= rect[3]  # <= Typo was here\n",
    "    subax = fig.add_axes([x,y,width,height],axisbg=axisbg)\n",
    "    x_labelsize = subax.get_xticklabels()[0].get_size()\n",
    "    y_labelsize = subax.get_yticklabels()[0].get_size()\n",
    "#     x_labelsize *= rect[2]**0.5\n",
    "#     y_labelsize *= rect[3]**0.5\n",
    "    subax.xaxis.set_tick_params(labelsize=x_labelsize)\n",
    "    subax.yaxis.set_tick_params(labelsize=y_labelsize)\n",
    "    return subax\n",
    "\n",
    "ChamberData=pd.read_csv('C:\\\\FishIsland_2017/ChamberFluxes.csv')\n",
    "plt.grid()\n",
    "ax = fig.add_subplot(111)\n",
    "rect = [0.75,0.695,0.2,0.33]\n",
    "ax1 = add_subplot_axes(ax,rect)\n",
    "ax1.boxplot(ChamberData['Flux'].dropna())\n",
    "# ax1.xaxis.set_major_formatter(NullFormatter())\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "plt.sca(ax1)\n",
    "plt.yticks([0,1,2])\n",
    "ax.set_title('GEP + ER Fit',fontsize = 24,loc='left')\n",
    "ax1.set_title('Chamber Fluxes',fontsize=20,y=1.05)\n",
    "ax.legend(loc='lower left',fontsize = 16)\n",
    "# plt.xticks('')\n",
    "\n",
    "\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('C:/Users/wesle/CompsProj/GapFilling.png',dpi=500)\n",
    "# print(popt_r,pcov)\n",
    "Data['TempFill']=pred2 = Light_Response_Temp2((Data['PPFD_Avg'],\n",
    "                       Data['Temp_2_5_1']),popt2[0],popt2[1],popt2[2],popt2[3],popt2[4],popt2[5])\n",
    "# np.nan\n",
    "Data['fco2_filled'] = Data['fco2'].fillna(Data['TempFill'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keys = ['fch4','wind_speed','NR_Wm2_Avg','VWC_1','AirTC_Avg','Time']\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Pool(5)\n",
    "    print(p.map(f, [1, 2, 3]))\n",
    "\n",
    "\n",
    "# keys = ['fch4','Rain_1D','u*','air_pressure','NR_Wm2_Avg','WtrTbl_Range','Temp_15_1','Active_Layer_1','Time']\n",
    " \n",
    "    \n",
    "    \n",
    "# Nodes = np.arange(2,10,1)\n",
    "# P = []\n",
    "# S = []\n",
    "# for node in Nodes:\n",
    "#     r2,mae,pred,std = SimpleANN(Data,\n",
    "#                     keys=keys,\n",
    "#                     node=node,iters=15,Verbose=False)\n",
    "#     P.append(mae)\n",
    "#     S.append(S)\n",
    "    \n",
    "# P = np.asanyarray(P)\n",
    "# S = np.asanyarray(S)\n",
    "# print(P)\n",
    "# plt.figure()\n",
    "# plt.eroorbar(Nodes,P,yerr=S)\n",
    "\n",
    "# nodes=Nodes[np.where(P == P.min())]\n",
    "\n",
    "# Results = SimpleANN(Data,keys=keys,node=nodes,iters=15,Verbose=False)\n",
    "# pred = Results[2]\n",
    "# Score = Results[0]\n",
    "# Data['Fill'] = np.nan\n",
    "# Temp = Data[keys[1:]].dropna()\n",
    "# Temp['Fill'] = pred\n",
    "# Data['Fill'] = Data['Fill'].fillna(Temp['Fill'])\n",
    "# print(Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# keys = ['fch4','wind_speed','NR_Wm2_Avg','VWC_1','AirTC_Avg','Time']\n",
    "\n",
    "# P = []\n",
    "# keys = ['fch4','Rain_1D','u*','air_pressure','PPFD_Avg','WtrTbl_Range',\n",
    "#         'Temp_15_1','Temp_2_5_1','Active_Layer_1','fco2_filled','Time']\n",
    "\n",
    "\n",
    "# keys = ['fch4','Rain_1D','u*','air_pressure','PPFD_Avg','WtrTbl_Range',\n",
    "#         'Temp_15_1','Temp_2_5_1','Active_Layer_1','Time']\n",
    "# keys = ['fch4','PPFD_Avg', 'Active_Layer_1', 'u*']\n",
    "\n",
    "# Node Search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Red = (.95,.25,.1,.45)\n",
    "plt.figure(figsize=(5.5,5.5))\n",
    "plt.scatter(Data['fch4'],Data['Fill'],label='r$^2$ = '+str(np.round(Score,3)),color=Red,s=15)\n",
    "plt.xlabel('Observed',fontsize = 16)\n",
    "plt.ylabel('Estimated',fontsize = 16)\n",
    "plt.grid()\n",
    "plt.xlim(Data['fch4'].min()-5,Data['fch4'].max()+5)\n",
    "plt.ylim(Data['fch4'].min()-5,Data['fch4'].max()+5)\n",
    "plt.plot([Data['fch4'].min(),Data['fch4'].max()],[Data['fch4'].min(),Data['fch4'].max()],\n",
    "        color='black',label='1:1')\n",
    "plt.legend(fontsize = 16)\n",
    "plt.title('Neural Network',fontsize=24)\n",
    "plt.tight_layout()\n",
    "plt.savefig('C:/Users/wesle/CompsProj/GapFilling_NN.png',dpi=500)\n",
    "\n",
    "Data['fch4_filled'] = Data['fch4'].fillna(Data['Fill'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# keys = ['fch4','Rain_1D','u*','air_pressure','PPFD_Avg','WtrTbl_Range',\n",
    "#         'Temp_15_1','Temp_2_5_1','Active_Layer_1','Time']\n",
    "\n",
    "def K_search(RunKeys,SearchKeys,K_min=None):\n",
    "    MAE = []\n",
    "    K = []\n",
    "    RK = RunKeys.copy()\n",
    "    for k in SearchKeys:\n",
    "        if k not in RunKeys:\n",
    "            RunKeys=RK.copy()\n",
    "            RunKeys.extend([k])\n",
    "            key = RunKeys\n",
    "            K.append(k)\n",
    "    #             print(key)\n",
    "            Results = SimpleANN(Data,keys=key,node=3,iters=10,Verbose=False)\n",
    "            MAE.append(Results[1])\n",
    "    MAE = np.asanyarray(MAE)\n",
    "#     K = np.asanyarray(K)\n",
    "    return(MAE,K)\n",
    "\n",
    "def Loop_Search(RunKey,keys):\n",
    "    rk2=RunKey.copy()\n",
    "    MAE, K = K_search(RunKey,keys[1:])\n",
    "    RunKey = rk2\n",
    "    K_min = K[np.where(MAE == MAE.min())[0][0]]\n",
    "    RunKey.append(K_min)\n",
    "    return(RunKey,K_min,MAE,K)\n",
    "    \n",
    "\n",
    "RunKey = [keys[0]]\n",
    "RunKey,K_min,MAE,K = Loop_Search(RunKey,keys)\n",
    "print(K_min)\n",
    "\n",
    "RunKey,K_min2,MAE2,K2 = Loop_Search(RunKey,keys)\n",
    "print(K_min2)\n",
    "\n",
    "\n",
    "RunKey,K_min3,MAE3,K3 = Loop_Search(RunKey,keys)\n",
    "print(K_min3)\n",
    "\n",
    "RunKey,K_min4,MAE4,K4 = Loop_Search(RunKey,keys)\n",
    "print(K_min4)\n",
    "\n",
    "print(RunKey)\n",
    "\n",
    "\n",
    "# plt.sca(ax[0,0])\n",
    "# plt.xticks(rotation=20)\n",
    "# plt.sca(ax[1,0])\n",
    "# plt.xticks(rotation=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fmt(K):\n",
    "    for i,k in enumerate(K):\n",
    "        k = k.replace('2_5','2.5')\n",
    "        k = k.replace('_15',' 15')\n",
    "        k = k.replace('_1','')\n",
    "        k = k.replace('_Avg','')\n",
    "        k = k.replace('_',' ')\n",
    "        K[i]=k\n",
    "    return(K)\n",
    "K=Fmt(K)\n",
    "K2=Fmt(K2)\n",
    "K3=Fmt(K3)\n",
    "K4=Fmt(K4)\n",
    "\n",
    "fig,ax=plt.subplots(2,2,figsize=(10,7))\n",
    "ax[0,0].bar(K,MAE)\n",
    "plt.sca(ax[0,0])\n",
    "plt.ylim(bottom=7)\n",
    "yl = ax[0,0].get_ylim()\n",
    "ax[0,0].grid()\n",
    "# ax[0,0].xaxis.set_major_formatter(NullFormatter())\n",
    "ax[0,0].set_title('One Factor',fontsize = 16)\n",
    "ax[0,0].set_ylabel('MAE nmol $m^{-2} s^{-1}$',fontsize = 16)\n",
    "plt.sca(ax[0,0])\n",
    "plt.xticks(rotation=35,fontsize=12)\n",
    "L = ax[0,0].xaxis.get_ticklabels()\n",
    "\n",
    "\n",
    "ax[0,1].bar(K2,MAE2)\n",
    "ax[0,1].set_ylim(ax[0,0].get_ylim())\n",
    "ax[0,1].grid()\n",
    "ax[0,1].set_title(K_min+'+',fontsize = 16)\n",
    "plt.sca(ax[0,1])\n",
    "plt.xticks(rotation=35,fontsize=12)\n",
    "# ax[1,0].xaxis.set_major_formatter(NullFormatter())\n",
    "\n",
    "ax[1,0].bar(K3,MAE3)\n",
    "ax[1,0].set_ylim(ax[0,0].get_ylim())\n",
    "ax[1,0].grid()\n",
    "ax[1,0].set_title(K_min+'+\\n'+K_min2+'+',fontsize = 14)\n",
    "ax[1,0].set_ylabel('MAE nmol $m^{-2} s^{-1}$',fontsize=16)\n",
    "plt.sca(ax[1,0])\n",
    "plt.xticks(rotation=35,fontsize=12)\n",
    "\n",
    "ax[1,1].bar(K4,MAE4)\n",
    "ax[1,1].set_ylim(ax[0,0].get_ylim())\n",
    "ax[1,1].set_title(K_min+'+\\n'+K_min2+'+'+K_min3+'+',fontsize = 16)\n",
    "ax[1,1].grid()\n",
    "plt.sca(ax[1,1])\n",
    "plt.xticks(rotation=35,fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('C:/Users/wesle/CompsProj/Feature_Selection.png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Green = (0,1,.1,.8)\n",
    "Daily = Data.resample('D').mean()\n",
    "fig,ax = plt.subplots(2,1,figsize = (10,7.5))\n",
    "\n",
    "Daily['fco2_filled']=Daily['fco2_filled']* 1e-6 * 44.0095 *3600*24\n",
    "\n",
    "Daily['fch4_filled']=Daily['fch4_filled']* 1e-6 * 16.04246 *3600*24\n",
    "\n",
    "Mn = Daily['fch4_filled'].mean()*28*1e-3+Daily['fco2_filled'].mean()\n",
    "\n",
    "print(-Mn*81/(365-81))\n",
    "print(Daily['fch4_filled'].count())\n",
    "print(Daily['fch4_filled'].mean()*28*1e-3+Daily['fco2_filled'].mean())\n",
    "\n",
    "ax[0].bar(Daily.index,Daily['fco2_filled'],color = Green,edgecolor = 'black',label='Daily F$_{CO2}$')\n",
    "ax[0].set_xlim('2017-06-22','2017-09-14')\n",
    "Daily['Mean']=Daily['fco2_filled'].mean()\n",
    "ax[0].plot(Daily['Mean'],color='black',label = 'Mean: '+ str(np.round(Daily['Mean'].mean(),2)))\n",
    "ax[0].grid()\n",
    "ax[0].set_ylabel('g m$^{-2}$ d$^{-1}$',fontsize = 16)\n",
    "ax[0].legend(loc=4,fontsize = 16)\n",
    "\n",
    "\n",
    "ax[1].bar(Daily.index,Daily['fch4_filled'],color = Red,edgecolor = 'black',label = 'Daily F$_{CH4}$')\n",
    "ax[1].set_xlim('2017-06-22','2017-09-14')\n",
    "Daily['Mean']=Daily['fch4_filled'].mean()\n",
    "ax[1].plot(Daily['Mean'],color='black',label = 'Mean: ' + str(np.round(Daily['Mean'].mean(),2)))\n",
    "ax[1].grid()\n",
    "ax[1].set_ylabel('mg m$^{-2}$ d$^{-1}$',fontsize = 16)\n",
    "ax[1].legend(loc = 1,fontsize = 16)\n",
    "\n",
    "# print(Daily['fco2_filled'].mean(),Daily['fco2'].mean())\n",
    "plt.tight_layout()\n",
    "plt.savefig('C:/Users/wesle/CompsProj/GHG_Balance.png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Scatter(Var,xl=None,yl=None):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.scatter(Fix[Var],NoFix[Var])\n",
    "    plt.xlabel('Fix')\n",
    "    plt.ylabel('NoFix')\n",
    "    if xl!=None:\n",
    "        plt.xlim(xl[0],xl[1])\n",
    "        plt.ylim(yl[0],yl[1])\n",
    "    plt.title(Var)\n",
    "\n",
    "# Scatter('Wind')\n",
    "# # Scatter('u*')\n",
    "# Scatter('co2_strg',[-2,2],[-2,2])\n",
    "# Scatter('qc_co2_flux')#,[-5,5],[-5,5])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.legend()\n",
    "# Scatter('H')\n",
    "# Scatter('LE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "\n",
    "\n",
    "for root,Dir,files in (os.walk(Root+'TagluStationData/Daily/')):\n",
    "    for i,file in enumerate(files):\n",
    "#         print(files,i)\n",
    "        df = pd.read_excel(root+file,sheetname=[0],skiprows=[0,2,3])[0]\n",
    "#         print(df.head())\n",
    "        df = df.set_index(pd.DatetimeIndex(df.TIMESTAMP))\n",
    "        if i == 0:\n",
    "            Daily = df\n",
    "        else:\n",
    "            Daily = Daily.append(df)\n",
    "#         df=df.resample('D').max()\n",
    "#         plt.plot(Hourly.index.dayofyear,Hourly['WindSpd']*3.6,color=(0,0,0,.5))\n",
    "#         plt.xlim(190,260)\n",
    "\n",
    "\n",
    "for root,Dir,files in (os.walk(Root+'TagluStationData/Hourly/')):\n",
    "    for i,file in enumerate(files):\n",
    "        df = pd.read_excel(root+file,sheetname=[0],skiprows=[0,1,3])[0]\n",
    "        df = df.set_index(pd.DatetimeIndex(df.TIMESTAMP))\n",
    "        if i == 0:\n",
    "            Hourly = df\n",
    "        else:\n",
    "            Hourly = Hourly.append(df)\n",
    "#         df=df.resample('D').mean()\n",
    "#         plt.plot(df.index.dayofyear,df['WindSpd']*3.6,color=(0,0,0,.75))\n",
    "#         plt.xlim(190,260)\n",
    "     \n",
    "    \n",
    "\n",
    "# plt.plot(Fix['Wind'].resample('D').mean().index.dayofyear,Fix['Wind'].resample('D').mean(),label='Fix',\n",
    "#         linewidth=4)\n",
    "# plt.plot(NoFix['Wind'].resample('D').mean().index.dayofyear,NoFix['Wind'].resample('D').mean(),label='NoFix',\n",
    "#         linewidth=4)\n",
    "\n",
    "# plt.ylim(0,30)\n",
    "\n",
    "# print(Daily.index.dayofyear)\n",
    "Daily.loc[Daily['Snow_Depth']<0] = np.nan\n",
    "Daily.loc[Daily['Snow_Depth']>1] = np.nan\n",
    "Daily['Snow_Depth'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly = Data.ffill().resample('M').mean()\n",
    "\n",
    "\n",
    "Daily.loc[Daily['Snow_Depth']<0] = np.nan\n",
    "Daily.loc[Daily['Snow_Depth']>.7] = np.nan\n",
    "Daily['Snow_Depth'].ffill()\n",
    "\n",
    "Data=Hourly.resample('D').mean()\n",
    "Data=Data.groupby(Data.index.dayofyear).mean()\n",
    "DailyData=Daily.groupby(Daily.index.dayofyear).mean()\n",
    "# print(Monthly)\n",
    "\n",
    "# print(Daily.head())\n",
    "\n",
    "fig,ax = plt.subplots(2,2,figsize=(10,10))\n",
    "\n",
    "ax1 = ax[0,0]\n",
    "ax2 = ax[0,1]\n",
    "ax3 = ax[1,0]\n",
    "ax4 = ax[1,1]\n",
    "\n",
    "ax1.plot(Data['AirTemp'])\n",
    "ax1.grid()\n",
    "ax1.set_title('Air Temperature')\n",
    "\n",
    "ax2.plot(Data['Net_Ttl_Rad_Avg'])\n",
    "ax2.grid()\n",
    "ax2.set_title('Net Radiation')\n",
    "\n",
    "ax3.plot(DailyData['Snow_Depth'])\n",
    "ax3.set_title('Snow Depth')\n",
    "# ax3.set_ylim(0,1)\n",
    "ax3.grid()\n",
    "\n",
    "ax4.plot(Data['SoilMoist(3)'])\n",
    "ax4.grid()\n",
    "ax4.set_title('Soil Moisture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(Daily['Snow_Depth'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    def Ustar_thresh_calc(self,Var,NightThresh):\n",
    "        \n",
    "        self.RawData['TempClass'] = np.nan\n",
    "        self.RawData['uClass'] = np.nan\n",
    "        self.RawData['uClass_Val'] = np.nan\n",
    "        self.RawData['ClassID'] = np.nan\n",
    "        self.RawData['ClassMean'] = np.nan\n",
    "        if NightThresh != None:\n",
    "            NightThresh == 1e4\n",
    "#             Data = self.RawData[((2.87/self.RawData['L']>0)&(2.87/self.RawData['L']<0.1))]\n",
    "            Data = self.RawData[((self.RawData['NR_Wm2_Avg']<NightThresh)&(np.isnan(self.RawData[Var])==False))]\n",
    "        else:\n",
    "            Data=self.RawData\n",
    "        Q = Data.quantile(np.arange(1,7,1)/6)['AirTC_Avg'].values\n",
    "        Q = np.insert(Q,0,Data['AirTC_Avg'].min())\n",
    "        for i,q in enumerate(Q):\n",
    "            Data.loc[Data['AirTC_Avg']>q,'TempClass']=i#+1\n",
    "            \n",
    "        for i,q in enumerate(Q):\n",
    "            qi = 0\n",
    "            Q2 = Data.loc[Data['TempClass']==i].quantile(np.arange(1,21,1)/20)['u*'].values\n",
    "            Q2 = np.insert(Q2,0,Data['u*'][Data['TempClass']==i].min())\n",
    "            for i2,q2 in enumerate(Q2[:-1]):\n",
    "                Data.loc[((Data['u*']>q2)&(Data['TempClass']==i)),'uClass']=i2\n",
    "                Data.loc[((Data['u*']>q2)&(Data['TempClass']==i)),'uClass_Val']=(Q2[i2+1]+q2)/2\n",
    "                Data.loc[((Data['u*']>q2)&(Data['TempClass']==i)),'ClassID']=i2+i*100\n",
    "                Data.loc[((Data['u*']>q2)&(Data['TempClass']==i)),'ClassMean'] = \\\n",
    "                    Data[Var][((Data['u*']>=q2)&(Data['TempClass']==i))].mean()\n",
    "#         self.RawData[((2.87/self.RawData['L']>0)&(2.87/self.RawData['L']<0.1))] = Data\n",
    "        self.RawData[((self.RawData['NR_Wm2_Avg']<NightThresh)&(np.isnan(self.RawData[Var])==False))] = Data\n",
    "#         plt.plot(self.RawData['ClassMean'])\n",
    "#         print(self.RawData['ClassMean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Data=Comp.Data.copy()\n",
    "\n",
    "print(Data['fch4'].mean())\n",
    "\n",
    "# fco2 = Daily['fco2']*1e-6 * 44.0095 *3600*24\n",
    "# fch4 = Daily['fch4']*1e-3 * 16.04246 *3600*24\n",
    "# print(fco2.mean())\n",
    "# print(fch4.mean())\n",
    "\n",
    "def QuickRegress(Data,time,periods,X,y):\n",
    "    Temp=Data.resample(time).mean()#[[X]].rolling(periods,min_periods=int(periods/2)).mean()\n",
    "#     Temp[y] = Data[y]\n",
    "#     plt.figure(figsize=(4,4))\n",
    "#     plt.scatter(Data[X],Data[y],color='red')\n",
    "    V = Temp[[X,y]].dropna()\n",
    "    lr = stats.linregress(V[X],V[y])\n",
    "    print()\n",
    "    print(lr[2]**2,lr[3])\n",
    "#     print(metrics.mean_absolute_error(V[y],V[X]*lr[0]+lr[1]))\n",
    "    Data[X] = Data[X].rolling(periods).mean()\n",
    "\n",
    "    Pred = Data[X]*lr[0]+lr[1]\n",
    "#     plt.scatter(Data[y],Pred,label=str(np.round(lr[2]**2,2))+str(np.round(lr[3],2)))\n",
    "#     plt.legend()\n",
    "#     plt.grid()\n",
    "    return(Pred)\n",
    "    \n",
    "    \n",
    "# print(Data['PPFD_Avg'])\n",
    "    \n",
    "# TimeScaleSearch(Data,'Table_1','fch4')\n",
    "\n",
    "# print(Data['PPFD_Avg'])\n",
    "\n",
    "# Data['PPFD_Avg_rolling']=Data['PPFD_Avg'].rolling(5*2).range()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TimeScaleSearch(Data,'VWC_1','fch4')\n",
    "# TimeScaleSearch(Data,'PPFD_Avg','fch4')\n",
    "# TimeScaleSearch(Data,'Temp_15_1','fch4')\n",
    "# TimeScaleSearch(Data,'Table_1','fch4')\n",
    "# TimeScaleSearch(Data,'Active_Layer_1','fch4')\n",
    "\n",
    "Time=['30T','1H','4H','3D','3D']\n",
    "Periods = [1,8,2,24,24]#,'2H','162H','162H']\n",
    "x = ['u*','Temp_15_1','PPFD_Avg','Active_Layer_1','Table_1']\n",
    "# Y = ['fch4','fch4','fch4','fch4','fch4']\n",
    "i = 1\n",
    "for time,p,X,y in zip(Time,Periods,x,Y):\n",
    "    p = QuickRegress(Data,time,p,X,'fch4')\n",
    "    if i ==1:\n",
    "        P = p\n",
    "    else:\n",
    "        P+=p\n",
    "    i+=1\n",
    "P/=i\n",
    "\n",
    "\n",
    "Data['Pred'] = P\n",
    "Score = Data[['fch4','Pred']].dropna()\n",
    "\n",
    "# print(metrics.mean_absolute_error(Score['fch4'],Score['Pred'])\n",
    "      \n",
    "# print(Score)\n",
    "print()\n",
    "r2 =(metrics.r2_score(Score['fch4'].values,Score['Pred'].values))\n",
    "\n",
    "\n",
    "# r2 = metrics.r2_score(Score['fch4'].values,Score['Pred'].values)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(Data['fch4'],P,label=str(np.round(r2,2)))\n",
    "plt.xlabel('True')\n",
    "plt.ylabel('Pred')\n",
    "plt.xlim(Data['fch4'].min(),Data['fch4'].max())\n",
    "plt.ylim(Data['fch4'].min(),Data['fch4'].max())\n",
    "plt.legend()\n",
    "    \n",
    "# plt.figure(figsize=(10,6))\n",
    "# plt.scatter(Daily['Table_1'],Daily['fch4'],color='red')\n",
    "# V = Daily[['Table_1','fch4']].dropna()\n",
    "# lr = stats.linregress(V['Table_1'],V['fch4'])\n",
    "# print(lr)\n",
    "# plt.plot(Daily['Table_1'],Daily['Table_1']*lr[0]+lr[1])\n",
    "noed=10\n",
    "print()\n",
    "\n",
    "# met = SimpleANN(Data,keys=['fch4','PPFD_Avg'],nodes=node)\n",
    "# print(met)\n",
    "\n",
    "# print()\n",
    "# met = SimpleANN(Data,keys=['fch4','PPFD_Avg_rolling'],nodes=node)\n",
    "# print(met)\n",
    "Data['Wtable_Range']=Data['Table_1'].rolling(24).max()-Data['Table_1'].rolling(24).min()\n",
    "Data['Pressure_D']=Data['air_pressure'].rolling(48).mean()-Data['air_pressure']#.rolling(48).min()\n",
    "Data['Rain_1D']=Data['Rain_mm_Tot'].rolling(48).sum()#Data['Table_1'].rolling(48).min()\n",
    "Data['Time'] = Data.index.hour\n",
    "Data['fch4']*=1000\n",
    "# print(Data['Wtable_Range'])\n",
    "# plt.figure()\n",
    "# plt.plot(Data['Wtable_Range'])\n",
    "# plt.plot(Data['Table_1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
